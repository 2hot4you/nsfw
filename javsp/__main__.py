import os
import re
import sys
import json
import time
import logging
from PIL import Image
from pydantic import ValidationError
from pydantic_extra_types.pendulum_dt import Duration
import requests
import threading
from typing import Dict, List
import datetime
import shutil

sys.stdout.reconfigure(encoding='utf-8')

import colorama
import pretty_errors
from colorama import Fore, Style
from tqdm import tqdm

from javsp.print import TqdmOut

# é…ç½®æ—¥å¿—æ ¼å¼ï¼Œä½¿å…¶æ›´åŠ ç¾è§‚
class ColoredFormatter(logging.Formatter):
    """è‡ªå®šä¹‰çš„å½©è‰²æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    COLORS = {
        'DEBUG': '\033[94m',     # è“è‰²
        'INFO': '\033[92m',      # ç»¿è‰²
        'WARNING': '\033[93m',   # é»„è‰²
        'ERROR': '\033[91m',     # çº¢è‰²
        'CRITICAL': '\033[95m',  # ç´«è‰²
        'RESET': '\033[0m'       # é‡ç½®
    }

    def format(self, record):
        # è·å–åŸå§‹çš„æ—¥å¿—æ¶ˆæ¯æ ¼å¼
        log_message = super().format(record)
        # æ·»åŠ é¢œè‰²
        if record.levelname in self.COLORS:
            log_message = f"{self.COLORS[record.levelname]}{log_message}{self.COLORS['RESET']}"
        return log_message

# è®¾ç½®æ—¥å¿—æ ¼å¼å’Œçº§åˆ«
def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    root_logger = logging.getLogger()
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(TqdmOut)
    
    # è®¾ç½®æ ¼å¼
    log_format = '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    formatter = ColoredFormatter(log_format, date_format)
    console_handler.setFormatter(formatter)
    
    # æ·»åŠ å¤„ç†å™¨
    root_logger.addHandler(console_handler)
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    root_logger.setLevel(logging.INFO)
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs('logs', exist_ok=True)
    
    # æ·»åŠ æ–‡ä»¶å¤„ç†å™¨
    current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    file_handler = logging.FileHandler(f'logs/javsp_{current_time}.log', encoding='utf-8')
    file_handler.setFormatter(logging.Formatter(log_format, date_format))
    root_logger.addHandler(file_handler)
    
    return root_logger

pretty_errors.configure(display_link=True)

# å°†StreamHandlerçš„streamä¿®æ”¹ä¸ºTqdmOutï¼Œä»¥ä¸TqdmååŒå·¥ä½œ
root_logger = logging.getLogger()
for handler in root_logger.handlers:
    if type(handler) == logging.StreamHandler:
        handler.stream = TqdmOut

# è®¾ç½®æ—¥å¿—
root_logger = setup_logging()
logger = logging.getLogger('main')

from javsp.cropper import Cropper, get_cropper

from javsp.lib import resource_path
from javsp.nfo import write_nfo
from javsp.file import *
from javsp.func import *
from javsp.image import *
from javsp.datatype import Movie, MovieInfo
from javsp.web.base import download
from javsp.web.exceptions import *
from javsp.web.translate import translate_movie_info
from javsp.telegram_notify import notifier  # å¯¼å…¥ Telegram é€šçŸ¥æ¨¡å—
from javsp.func import set_current_movie_info, get_current_movie_info  # å¯¼å…¥å½±ç‰‡ä¿¡æ¯å…±äº«å‡½æ•°

from javsp.config import Cfg, CrawlerID
from javsp.prompt import prompt

actressAliasMap = {}

def resolve_alias(name):
    """å°†åˆ«åè§£æä¸ºå›ºå®šçš„åå­—"""
    for fixedName, aliases in actressAliasMap.items():
        if name in aliases:
            return fixedName
    return name  # å¦‚æœæ‰¾ä¸åˆ°åˆ«åå¯¹åº”çš„å›ºå®šåå­—ï¼Œåˆ™è¿”å›åŸå


def import_crawlers():
    """æŒ‰é…ç½®æ–‡ä»¶çš„æŠ“å–å™¨é¡ºåºå°†è¯¥å­—æ®µè½¬æ¢ä¸ºæŠ“å–å™¨çš„å‡½æ•°åˆ—è¡¨"""
    unknown_mods = []
    for _, mods in Cfg().crawler.selection.items():
        valid_mods = []
        for name in mods:
            try:
                # å¯¼å…¥fc2fanæŠ“å–å™¨çš„å‰æ: é…ç½®äº†fc2fançš„æœ¬åœ°è·¯å¾„
                # if name == 'fc2fan' and (not os.path.isdir(Cfg().Crawler.fc2fan_local_path)):
                #     logger.debug('ç”±äºæœªé…ç½®æœ‰æ•ˆçš„fc2fanè·¯å¾„ï¼Œå·²è·³è¿‡è¯¥æŠ“å–å™¨')
                #     continue
                import_name = 'javsp.web.' + name
                __import__(import_name)
                valid_mods.append(import_name)  # æŠ“å–å™¨æœ‰æ•ˆ: ä½¿ç”¨å®Œæ•´æ¨¡å—è·¯å¾„ï¼Œä¾¿äºç¨‹åºå®é™…ä½¿ç”¨
            except ModuleNotFoundError:
                unknown_mods.append(name)       # æŠ“å–å™¨æ— æ•ˆ: ä»…ä½¿ç”¨æ¨¡å—åï¼Œä¾¿äºæ˜¾ç¤º
    if unknown_mods:
        logger.warning('é…ç½®çš„æŠ“å–å™¨æ— æ•ˆ: ' + ', '.join(unknown_mods))


# çˆ¬è™«æ˜¯IOå¯†é›†å‹ä»»åŠ¡ï¼Œå¯ä»¥é€šè¿‡å¤šçº¿ç¨‹æå‡æ•ˆç‡
def parallel_crawler(movie: Movie, tqdm_bar=None):
    """ä½¿ç”¨å¤šçº¿ç¨‹æŠ“å–ä¸åŒç½‘ç«™çš„æ•°æ®"""
    def wrapper(parser, info: MovieInfo, retry):
        """å¯¹æŠ“å–å™¨å‡½æ•°è¿›è¡ŒåŒ…è£…ï¼Œä¾¿äºæ›´æ–°æç¤ºä¿¡æ¯å’Œè‡ªåŠ¨é‡è¯•"""
        crawler_name = threading.current_thread().name
        task_info = f'Crawler: {crawler_name}: {info.dvdid}'
        for cnt in range(retry):
            try:
                parser(info)
                movie_id = info.dvdid or info.cid
                logger.debug(f"ğŸ¬ {crawler_name}: æŠ“å–æˆåŠŸ '{movie_id}' âœ…")
                logger.debug(f"ğŸ”— {crawler_name}: æ¥æºåœ°å€ '{info.url}'")
                setattr(info, 'success', True)
                if isinstance(tqdm_bar, tqdm):
                    tqdm_bar.set_description(f'ğŸ¬ {crawler_name}: æŠ“å–å®Œæˆ')
                break
            except MovieNotFoundError as e:
                logger.debug(f"âš ï¸ {crawler_name}: å½±ç‰‡æœªæ‰¾åˆ° - {str(e)}")
                break
            except MovieDuplicateError as e:
                logger.exception(f"âš ï¸ {crawler_name}: é‡å¤å½±ç‰‡ - {str(e)}")
                break
            except (SiteBlocked, SitePermissionError, CredentialError) as e:
                logger.error(f"ğŸš« {crawler_name}: ç«™ç‚¹è®¿é—®å—é™ - {str(e)}")
                break
            except requests.exceptions.RequestException as e:
                logger.debug(f'ğŸ”„ {crawler_name}: ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•ä¸­ ({cnt+1}/{retry})\n  åŸå› : {repr(e)}')
                if isinstance(tqdm_bar, tqdm):
                    tqdm_bar.set_description(f'ğŸ”„ {crawler_name}: ç½‘ç»œé”™è¯¯ï¼Œé‡è¯•ä¸­')
            except Exception as e:
                logger.exception(f"âŒ {crawler_name}: æœªçŸ¥é”™è¯¯ - {str(e)}")

    # æ ¹æ®å½±ç‰‡çš„æ•°æ®æºè·å–å¯¹åº”çš„æŠ“å–å™¨
    crawler_mods: List[CrawlerID] = Cfg().crawler.selection[movie.data_src]

    all_info = {i.value: MovieInfo(movie) for i in crawler_mods}
    # ç•ªå·ä¸ºcidä½†åŒæ—¶ä¹Ÿæœ‰æœ‰æ•ˆçš„dvdidæ—¶ï¼Œä¹Ÿå°è¯•ä½¿ç”¨æ™®é€šæ¨¡å¼è¿›è¡ŒæŠ“å–
    if movie.data_src == 'cid' and movie.dvdid:
        crawler_mods = crawler_mods + Cfg().crawler.selection.normal
        for i in all_info.values():
            i.dvdid = None
        for i in Cfg().crawler.selection.normal:
            all_info[i.value] = MovieInfo(movie.dvdid)
    thread_pool = []
    for mod_partial, info in all_info.items():
        mod = f"javsp.web.{mod_partial}"
        parser = getattr(sys.modules[mod], 'parse_data')
        # å°†all_infoä¸­çš„infoå®ä¾‹ä¼ é€’ç»™parserï¼ŒparseræŠ“å–å®Œæˆåï¼Œinfoå®ä¾‹çš„å€¼å·²ç»å®Œæˆæ›´æ–°
        # TODO: æŠ“å–å™¨å¦‚æœå¸¦æœ‰parse_data_rawï¼Œè¯´æ˜å®ƒå·²ç»è‡ªè¡Œè¿›è¡Œäº†é‡è¯•å¤„ç†ï¼Œæ­¤æ—¶å°†é‡è¯•æ¬¡æ•°è®¾ç½®ä¸º1
        if hasattr(sys.modules[mod], 'parse_data_raw'):
            th = threading.Thread(target=wrapper, name=mod, args=(parser, info, 1))
        else:
            th = threading.Thread(target=wrapper, name=mod, args=(parser, info, Cfg().network.retry))
        th.start()
        thread_pool.append(th)
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
    timeout = Cfg().network.retry * Cfg().network.timeout.total_seconds()
    for th in thread_pool:
        th: threading.Thread
        th.join(timeout=timeout)
    # æ ¹æ®æŠ“å–ç»“æœæ›´æ–°å½±ç‰‡ç±»å‹åˆ¤å®š
    if movie.data_src == 'cid' and movie.dvdid:
        titles = [all_info[i].title for i in Cfg().crawler.selection[movie.data_src]]
        if any(titles):
            movie.dvdid = None
            all_info = {k: v for k, v in all_info.items() if k in Cfg().crawler.selection['cid']}
        else:
            logger.debug(f'è‡ªåŠ¨æ›´æ­£å½±ç‰‡æ•°æ®æºç±»å‹: {movie.dvdid} ({movie.cid}): normal')
            movie.data_src = 'normal'
            movie.cid = None
            all_info = {k: v for k, v in all_info.items() if k not in Cfg().crawler.selection['cid']}
    # åˆ é™¤æŠ“å–å¤±è´¥çš„ç«™ç‚¹å¯¹åº”çš„æ•°æ®
    all_info = {k:v for k,v in all_info.items() if hasattr(v, 'success')}
    for info in all_info.values():
        del info.success
    # åˆ é™¤all_infoä¸­é”®åä¸­çš„'web.'
    all_info = {k[4:]:v for k,v in all_info.items()}
    return all_info


def info_summary(movie: Movie, all_info: Dict[str, MovieInfo]):
    """æ±‡æ€»å¤šä¸ªæ¥æºçš„åœ¨çº¿æ•°æ®ç”Ÿæˆæœ€ç»ˆæ•°æ®"""
    final_info = MovieInfo(movie)
    logger.info(f"ğŸ“Š å¼€å§‹æ±‡æ€»å½±ç‰‡ {movie.dvdid or movie.cid} çš„å…ƒæ•°æ®")
    
    ########## éƒ¨åˆ†å­—æ®µé…ç½®äº†ä¸“é—¨çš„é€‰å–é€»è¾‘ï¼Œå…ˆå¤„ç†è¿™äº›å­—æ®µ ##########
    # genre
    if 'javdb' in all_info and all_info['javdb'].genre:
        logger.debug(f"ğŸ·ï¸ ä½¿ç”¨ javdb çš„æ ‡ç­¾åˆ†ç±»")
        final_info.genre = all_info['javdb'].genre

    ########## ç§»é™¤æ‰€æœ‰æŠ“å–å™¨æ•°æ®ä¸­ï¼Œæ ‡é¢˜å°¾éƒ¨çš„å¥³ä¼˜å ##########
    if Cfg().summarizer.title.remove_trailing_actor_name:
        for name, data in all_info.items():
            old_title = data.title
            data.title = remove_trail_actor_in_title(data.title, data.actress)
            if old_title != data.title:
                logger.debug(f"ğŸ“ {name}: ä»æ ‡é¢˜ä¸­ç§»é™¤å¥³ä¼˜å: '{old_title}' -> '{data.title}'")
                
    ########## ç„¶åæ£€æŸ¥æ‰€æœ‰å­—æ®µï¼Œå¦‚æœæŸä¸ªå­—æ®µè¿˜æ˜¯é»˜è®¤å€¼ï¼Œåˆ™æŒ‰ç…§ä¼˜å…ˆçº§é€‰å–æ•°æ® ##########
    # parserç›´æ¥æ›´æ–°äº†all_infoä¸­çš„é¡¹ç›®ï¼Œè€Œåˆå§‹all_infoæ˜¯æŒ‰ç…§ä¼˜å…ˆçº§ç”Ÿæˆçš„ï¼Œå·²ç»ç¬¦åˆé…ç½®çš„ä¼˜å…ˆçº§é¡ºåºäº†
    # æŒ‰ç…§ä¼˜å…ˆçº§å–å‡ºå„ä¸ªçˆ¬è™«è·å–åˆ°çš„ä¿¡æ¯
    attrs = [i for i in dir(final_info) if not i.startswith('_')]
    covers, big_covers = [], []
    for name, data in all_info.items():
        absorbed = []
        # éå†æ‰€æœ‰å±æ€§ï¼Œå¦‚æœæŸä¸€å±æ€§å½“å‰å€¼ä¸ºç©ºè€Œçˆ¬å–çš„æ•°æ®ä¸­å«æœ‰è¯¥å±æ€§ï¼Œåˆ™é‡‡ç”¨çˆ¬è™«çš„å±æ€§
        for attr in attrs:
            incoming = getattr(data, attr)
            current = getattr(final_info, attr)
            if attr == 'cover':
                if incoming and (incoming not in covers):
                    covers.append(incoming)
                    absorbed.append(f"{attr} ({len(covers)})")
            elif attr == 'big_cover':
                if incoming and (incoming not in big_covers):
                    big_covers.append(incoming)
                    absorbed.append(f"{attr} ({len(big_covers)})")
            elif attr == 'uncensored':
                if (current is None) and (incoming is not None):
                    setattr(final_info, attr, incoming)
                    absorbed.append(attr)
            else:
                if (not current) and (incoming):
                    setattr(final_info, attr, incoming)
                    absorbed.append(attr)
        if absorbed:
            logger.debug(f"ğŸ“¥ ä» '{name}' ä¸­è·å–äº†: " + ', '.join(absorbed))
    
    # ä½¿ç”¨ç½‘ç«™çš„ç•ªå·ä½œä¸ºç•ªå·
    if Cfg().crawler.respect_site_avid:
        id_weight = {}
        for name, data in all_info.items():
            if data.title:
                if movie.dvdid:
                    id_weight.setdefault(data.dvdid, []).append(name)
                else:
                    id_weight.setdefault(data.cid, []).append(name)
        # æ ¹æ®æƒé‡é€‰æ‹©æœ€ç»ˆç•ªå·
        if id_weight:
            id_weight = {k:v for k, v in sorted(id_weight.items(), key=lambda x:len(x[1]), reverse=True)}
            final_id = list(id_weight.keys())[0]
            sources = ', '.join(id_weight[final_id])
            if movie.dvdid:
                old_id = final_info.dvdid
                final_info.dvdid = final_id
                if old_id != final_id:
                    logger.debug(f"ğŸ”¢ ä¿®æ­£ç•ªå·: {old_id} -> {final_id} (æ¥æº: {sources})")
            else:
                old_id = final_info.cid
                final_info.cid = final_id
                if old_id != final_id:
                    logger.debug(f"ğŸ”¢ ä¿®æ­£ç•ªå·: {old_id} -> {final_id} (æ¥æº: {sources})")
    
    # javdbå°é¢æœ‰æ°´å°ï¼Œä¼˜å…ˆé‡‡ç”¨å…¶ä»–ç«™ç‚¹çš„å°é¢
    javdb_cover = getattr(all_info.get('javdb'), 'cover', None)
    if javdb_cover is not None:
        match Cfg().crawler.use_javdb_cover:
            case UseJavDBCover.fallback:
                covers.remove(javdb_cover)
                covers.append(javdb_cover)
            case UseJavDBCover.no:
                covers.remove(javdb_cover)

    setattr(final_info, 'covers', covers)
    setattr(final_info, 'big_covers', big_covers)
    # å¯¹coverå’Œbig_coverèµ‹å€¼ï¼Œé¿å…åç»­æ£€æŸ¥å¿…é¡»å­—æ®µæ—¶å‡ºé”™
    if covers:
        final_info.cover = covers[0]
    if big_covers:
        final_info.big_cover = big_covers[0]
    ########## éƒ¨åˆ†å­—æ®µæ”¾åœ¨æœ€åè¿›è¡Œæ£€æŸ¥ ##########
    # ç‰¹æ®Šçš„ genre
    if final_info.genre is None:
        final_info.genre = []
    if movie.hard_sub:
        final_info.genre.append('å†…åµŒå­—å¹•')
    if movie.uncensored:
        final_info.genre.append('æ— ç æµå‡º/ç ´è§£')

    # å¥³ä¼˜åˆ«åå›ºå®š
    if Cfg().crawler.normalize_actress_name and bool(final_info.actress_pics):
        final_info.actress = [resolve_alias(i) for i in final_info.actress]
        if final_info.actress_pics:
            final_info.actress_pics = {
                resolve_alias(key): value for key, value in final_info.actress_pics.items()
            }

    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€çš„å­—æ®µéƒ½å·²ç»è·å¾—äº†å€¼
    for attr in Cfg().crawler.required_keys:
        if not getattr(final_info, attr, None):
            logger.error(f"æ‰€æœ‰æŠ“å–å™¨å‡æœªè·å–åˆ°å­—æ®µ: '{attr}'ï¼ŒæŠ“å–å¤±è´¥")
            return False
    # å¿…éœ€å­—æ®µå‡å·²è·å¾—äº†å€¼ï¼šå°†æœ€ç»ˆçš„æ•°æ®é™„åŠ åˆ°movie
    movie.info = final_info
    return True

def generate_names(movie: Movie):
    """æŒ‰ç…§æ¨¡æ¿ç”Ÿæˆç›¸å…³æ–‡ä»¶çš„æ–‡ä»¶å"""

    def legalize_path(path: str):
        """
            Windowsä¸‹æ–‡ä»¶åä¸­ä¸èƒ½åŒ…å«æ¢è¡Œ #467
            æ‰€ä»¥è¿™é‡Œå¯¹æ–‡ä»¶è·¯å¾„è¿›è¡Œåˆæ³•åŒ–
        """
        return ''.join(c for c in path if c not in {'\n'})

    info = movie.info
    # å‡†å¤‡ç”¨æ¥å¡«å……å‘½åæ¨¡æ¿çš„å­—å…¸
    d = info.get_info_dic()

    if info.actress and len(info.actress) > Cfg().summarizer.path.max_actress_count:
        logging.debug('å¥³ä¼˜äººæ•°è¿‡å¤šï¼ŒæŒ‰é…ç½®ä¿ç•™äº†å…¶ä¸­çš„å‰nä¸ª: ' + ','.join(info.actress))
        actress = info.actress[:Cfg().summarizer.path.max_actress_count] + ['â€¦']
    else:
        actress = info.actress
    d['actress'] = ','.join(actress) if actress else Cfg().summarizer.default.actress

    # ä¿å­˜labelä¾›åé¢åˆ¤æ–­è£å‰ªå›¾ç‰‡çš„æ–¹å¼ä½¿ç”¨
    setattr(info, 'label', d['label'].upper())
    # å¤„ç†å­—æ®µï¼šæ›¿æ¢ä¸èƒ½ä½œä¸ºæ–‡ä»¶åçš„å­—ç¬¦ï¼Œç§»é™¤é¦–å°¾çš„ç©ºå­—ç¬¦
    for k, v in d.items():
        d[k] = replace_illegal_chars(v.strip())

    # ç”Ÿæˆnfoæ–‡ä»¶ä¸­çš„å½±ç‰‡æ ‡é¢˜
    nfo_title = Cfg().summarizer.nfo.title_pattern.format(**d)
    setattr(info, 'nfo_title', nfo_title)
    
    # ä½¿ç”¨å­—å…¸å¡«å……æ¨¡æ¿ï¼Œç”Ÿæˆç›¸å…³æ–‡ä»¶çš„è·¯å¾„ï¼ˆå¤šåˆ†ç‰‡å½±ç‰‡è¦è€ƒè™‘CD-xéƒ¨åˆ†ï¼‰
    cdx = '' if len(movie.files) <= 1 else '-CD1'
    if hasattr(info, 'title_break'):
        title_break = info.title_break
    else:
        title_break = split_by_punc(d['title'])
    if hasattr(info, 'ori_title_break'):
        ori_title_break = info.ori_title_break
    else:
        ori_title_break = split_by_punc(d['rawtitle'])
    copyd = d.copy()

    def legalize_info():
        if movie.save_dir != None:
            movie.save_dir = legalize_path(movie.save_dir)
        if movie.nfo_file != None:
            movie.nfo_file = legalize_path(movie.nfo_file)
        if movie.fanart_file != None:
            movie.fanart_file = legalize_path(movie.fanart_file)
        if movie.poster_file != None:
            movie.poster_file = legalize_path(movie.poster_file)
        if d['title'] != copyd['title']:
            logger.info(f"è‡ªåŠ¨æˆªçŸ­æ ‡é¢˜ä¸º:\n{copyd['title']}")
        if d['rawtitle'] != copyd['rawtitle']:
            logger.info(f"è‡ªåŠ¨æˆªçŸ­åŸå§‹æ ‡é¢˜ä¸º:\n{copyd['rawtitle']}")
        return

    copyd['num'] = copyd['num'] + movie.attr_str
    longest_ext = max((os.path.splitext(i)[1] for i in movie.files), key=len)
    for end in range(len(ori_title_break), 0, -1):
        copyd['rawtitle'] = replace_illegal_chars(''.join(ori_title_break[:end]).strip())
        for sub_end in range(len(title_break), 0, -1):
            copyd['title'] = replace_illegal_chars(''.join(title_break[:sub_end]).strip())
            if Cfg().summarizer.move_files:
                save_dir = os.path.normpath(Cfg().summarizer.path.output_folder_pattern.format(**copyd)).strip()
                basename = os.path.normpath(Cfg().summarizer.path.basename_pattern.format(**copyd)).strip()
            else:
                # å¦‚æœä¸æ•´ç†æ–‡ä»¶ï¼Œåˆ™ä¿å­˜æŠ“å–çš„æ•°æ®åˆ°å½“å‰ç›®å½•
                save_dir = os.path.dirname(movie.files[0])
                filebasename = os.path.basename(movie.files[0])
                ext = os.path.splitext(filebasename)[1]
                basename = filebasename.replace(ext, '')
            long_path = os.path.join(save_dir, basename+longest_ext)
            remaining = get_remaining_path_len(os.path.abspath(long_path))
            if remaining > 0:
                movie.save_dir = save_dir
                movie.basename = basename
                movie.nfo_file = os.path.join(save_dir, Cfg().summarizer.nfo.basename_pattern.format(**copyd) + '.nfo')
                movie.fanart_file = os.path.join(save_dir, Cfg().summarizer.fanart.basename_pattern.format(**copyd) + '.jpg')
                movie.poster_file = os.path.join(save_dir, Cfg().summarizer.cover.basename_pattern.format(**copyd) + '.jpg')
                return legalize_info()
    else:
        # ä»¥é˜²ä¸‡ä¸€ï¼Œå½“æ•´ç†è·¯å¾„éå¸¸æ·±æˆ–è€…æ ‡é¢˜èµ·å§‹å¾ˆé•¿ä¸€æ®µæ²¡æœ‰æ ‡ç‚¹ç¬¦å·æ—¶ï¼Œç¡¬æ€§æˆªçŸ­ç”Ÿæˆçš„åç§°
        copyd['title'] = copyd['title'][:remaining]
        copyd['rawtitle'] = copyd['rawtitle'][:remaining]
        # å¦‚æœä¸æ•´ç†æ–‡ä»¶ï¼Œåˆ™ä¿å­˜æŠ“å–çš„æ•°æ®åˆ°å½“å‰ç›®å½•
        if not Cfg().summarizer.move_files:
            save_dir = os.path.dirname(movie.files[0])
            filebasename = os.path.basename(movie.files[0])
            ext = os.path.splitext(filebasename)[1]
            basename = filebasename.replace(ext, '')
        else:
            save_dir = os.path.normpath(Cfg().summarizer.path.output_folder_pattern.format(**copyd)).strip()
            basename = os.path.normpath(Cfg().summarizer.path.basename_pattern.format(**copyd)).strip()
        movie.save_dir = save_dir
        movie.basename = basename

        movie.nfo_file = os.path.join(save_dir, Cfg().summarizer.nfo.basename_pattern.format(**copyd) + '.nfo')
        movie.fanart_file = os.path.join(save_dir, Cfg().summarizer.fanart.basename_pattern.format(**copyd) + '.jpg')
        movie.poster_file = os.path.join(save_dir, Cfg().summarizer.cover.basename_pattern.format(**copyd) + '.jpg')

        return legalize_info()

def reviewMovieID(all_movies, root):
    """äººå·¥æ£€æŸ¥æ¯ä¸€éƒ¨å½±ç‰‡çš„ç•ªå·"""
    count = len(all_movies)
    logger.info('è¿›å…¥æ‰‹åŠ¨æ¨¡å¼æ£€æŸ¥ç•ªå·: ')
    for i, movie in enumerate(all_movies, start=1):
        id = repr(movie)[7:-2]
        print(f'[{i}/{count}]\t{Fore.LIGHTMAGENTA_EX}{id}{Style.RESET_ALL}, å¯¹åº”æ–‡ä»¶:')
        relpaths = [os.path.relpath(i, root) for i in movie.files]
        print('\n'.join(['  '+i for i in relpaths]))
        s = prompt("å›è½¦ç¡®è®¤å½“å‰ç•ªå·ï¼Œæˆ–ç›´æ¥è¾“å…¥æ›´æ­£åçš„ç•ªå·ï¼ˆå¦‚'ABC-123'æˆ–'cid:sqte00300'ï¼‰", "æ›´æ­£åçš„ç•ªå·")
        if not s:
            logger.info(f"å·²ç¡®è®¤å½±ç‰‡ç•ªå·: {','.join(relpaths)}: {id}")
        else:
            s = s.strip()
            s_lc = s.lower()
            if s_lc.startswith(('cid:', 'cid=')):
                new_movie = Movie(cid=s_lc[4:])
                new_movie.data_src = 'cid'
                new_movie.files = movie.files
            elif s_lc.startswith('fc2'):
                new_movie = Movie(s)
                new_movie.data_src = 'fc2'
                new_movie.files = movie.files
            else:
                new_movie = Movie(s)
                new_movie.data_src = 'normal'
                new_movie.files = movie.files
            all_movies[i-1] = new_movie
            new_id = repr(new_movie)[7:-2]
            logger.info(f"å·²æ›´æ­£å½±ç‰‡ç•ªå·: {','.join(relpaths)}: {id} -> {new_id}")
        print()


SUBTITLE_MARK_FILE = Image.open(os.path.abspath(resource_path('image/sub_mark.png')))
UNCENSORED_MARK_FILE = Image.open(os.path.abspath(resource_path('image/unc_mark.png')))

def process_poster(movie: Movie):
    def should_use_ai_crop_match(label):
        for r in Cfg().summarizer.cover.crop.on_id_pattern:
            if re.match(r, label):
                return True
        return False
    crop_engine = None
    if (movie.info.uncensored or
       movie.data_src == 'fc2' or
       should_use_ai_crop_match(movie.info.label.upper())):
        crop_engine = Cfg().summarizer.cover.crop.engine
    cropper = get_cropper(crop_engine)
    fanart_image = Image.open(movie.fanart_file)
    fanart_cropped = cropper.crop(fanart_image)

    if Cfg().summarizer.cover.add_label:
        if movie.hard_sub:
            fanart_cropped = add_label_to_poster(fanart_cropped, SUBTITLE_MARK_FILE, LabelPostion.BOTTOM_RIGHT)
        if movie.uncensored:
            fanart_cropped = add_label_to_poster(fanart_cropped, UNCENSORED_MARK_FILE, LabelPostion.BOTTOM_LEFT)
    fanart_cropped.save(movie.poster_file)

def RunNormalMode(all_movies):
    """æ™®é€šæ•´ç†æ¨¡å¼"""
    def check_step(result, msg='æ­¥éª¤é”™è¯¯'):
        """æ£€æŸ¥ä¸€ä¸ªæ•´ç†æ­¥éª¤çš„ç»“æœï¼Œå¹¶è´Ÿè´£æ›´æ–°tqdmçš„è¿›åº¦"""
        if result:
            inner_bar.update()
        else:
            raise Exception(msg + '\n')

    outer_bar = tqdm(all_movies, desc='æ•´ç†å½±ç‰‡', ascii=True, leave=False)
    total_step = 6
    if Cfg().translator.engine:
        total_step += 1
    if Cfg().summarizer.extra_fanarts.enabled:
        total_step += 1

    return_movies = []
    success_count = 0
    failed_count = 0
    
    for movie in outer_bar:
        try:
            # åˆå§‹åŒ–æœ¬æ¬¡å¾ªç¯è¦æ•´ç†å½±ç‰‡ä»»åŠ¡
            filenames = [os.path.split(i)[1] for i in movie.files]
            logger.info('æ­£åœ¨æ•´ç†: ' + ', '.join(filenames))
            inner_bar = tqdm(total=total_step, desc='æ­¥éª¤', ascii=True, leave=False)
            # ä¾æ¬¡æ‰§è¡Œå„ä¸ªæ­¥éª¤
            inner_bar.set_description(f'å¯åŠ¨å¹¶å‘ä»»åŠ¡')
            all_info = parallel_crawler(movie, inner_bar)
            msg = f'ä¸ºå…¶é…ç½®çš„{len(Cfg().crawler.selection[movie.data_src])}ä¸ªæŠ“å–å™¨å‡æœªè·å–åˆ°å½±ç‰‡ä¿¡æ¯'
            check_step(all_info, msg)

            inner_bar.set_description('æ±‡æ€»æ•°æ®')
            has_required_keys = info_summary(movie, all_info)
            check_step(has_required_keys)
            
            # è®¾ç½®å½“å‰å½±ç‰‡ä¿¡æ¯ï¼Œä¾›é€šçŸ¥ç³»ç»Ÿä½¿ç”¨
            set_current_movie_info(movie.info)

            if Cfg().translator.engine:
                inner_bar.set_description('ç¿»è¯‘å½±ç‰‡ä¿¡æ¯')
                success = translate_movie_info(movie.info)
                check_step(success)

            generate_names(movie)
            check_step(movie.save_dir, 'æ— æ³•æŒ‰å‘½åè§„åˆ™ç”Ÿæˆç›®æ ‡æ–‡ä»¶å¤¹')
            if not os.path.exists(movie.save_dir):
                os.makedirs(movie.save_dir)

            inner_bar.set_description('ä¸‹è½½å°é¢å›¾ç‰‡')
            if Cfg().summarizer.cover.highres:
                cover_dl = download_cover(movie.info.covers, movie.fanart_file, movie.info.big_covers)
            else:
                cover_dl = download_cover(movie.info.covers, movie.fanart_file)
            check_step(cover_dl, 'ä¸‹è½½å°é¢å›¾ç‰‡å¤±è´¥')
            cover, pic_path = cover_dl
            # ç¡®ä¿å®é™…ä¸‹è½½çš„å°é¢çš„urlä¸å³å°†å†™å…¥åˆ°movie.infoä¸­çš„ä¸€è‡´
            if cover != movie.info.cover:
                movie.info.cover = cover
            # æ ¹æ®å®é™…ä¸‹è½½çš„å°é¢çš„æ ¼å¼æ›´æ–°fanart/posterç­‰å›¾ç‰‡çš„æ–‡ä»¶å
            if pic_path != movie.fanart_file:
                movie.fanart_file = pic_path
                actual_ext = os.path.splitext(pic_path)[1]
                movie.poster_file = os.path.splitext(movie.poster_file)[0] + actual_ext

            process_poster(movie)

            check_step(True)

            if Cfg().summarizer.extra_fanarts.enabled:
                scrape_interval = Cfg().summarizer.extra_fanarts.scrap_interval.total_seconds()
                inner_bar.set_description('ä¸‹è½½å‰§ç…§')
                if movie.info.preview_pics:
                    extrafanartdir = movie.save_dir + '/extrafanart'
                    os.mkdir(extrafanartdir)
                    for (id, pic_url) in enumerate(movie.info.preview_pics):
                        inner_bar.set_description(f"Downloading extrafanart {id} from url: {pic_url}")
                                                                                                                                
                        fanart_destination = f"{extrafanartdir}/{id}.png"
                        try:
                            info = download(pic_url, fanart_destination)
                            if valid_pic(fanart_destination):
                                filesize = get_fmt_size(pic_path)
                                width, height = get_pic_size(pic_path)
                                elapsed = time.strftime("%M:%S", time.gmtime(info['elapsed']))
                                speed = get_fmt_size(info['rate']) + '/s'
                                logger.info(f"å·²ä¸‹è½½å‰§ç…§{pic_url} {id}.png: {width}x{height}, {filesize} [{elapsed}, {speed}]")
                            else:
                                check_step(False, f"ä¸‹è½½å‰§ç…§{id}: {pic_url}å¤±è´¥")
                        except:
                            check_step(False, f"ä¸‹è½½å‰§ç…§{id}: {pic_url}å¤±è´¥")
                        time.sleep(scrape_interval)
                check_step(True)

            inner_bar.set_description('å†™å…¥NFO')
            write_nfo(movie.info, movie.nfo_file)
            check_step(True)
            if Cfg().summarizer.move_files:
                inner_bar.set_description('ç§»åŠ¨å½±ç‰‡æ–‡ä»¶')
                movie.rename_files(Cfg().summarizer.path.hard_link)
                check_step(True)
                logger.info(f'æ•´ç†å®Œæˆï¼Œç›¸å…³æ–‡ä»¶å·²ä¿å­˜åˆ°: {movie.save_dir}\n')
            else:
                logger.info(f'åˆ®å‰Šå®Œæˆï¼Œç›¸å…³æ–‡ä»¶å·²ä¿å­˜åˆ°: {movie.nfo_file}\n')
            
            # å‘é€ Telegram æˆåŠŸé€šçŸ¥
            movie_id = movie.dvdid or movie.cid
            notifier.send_success_notification(
                movie_title=movie.info.title, 
                movie_id=movie_id,
                save_dir=movie.save_dir,
                poster_path=movie.poster_file
            )
            
            success_count += 1
            
            if movie != all_movies[-1] and Cfg().crawler.sleep_after_scraping > Duration(0):
                time.sleep(Cfg().crawler.sleep_after_scraping.total_seconds())
            return_movies.append(movie)
        except Exception as e:
            logger.debug(e, exc_info=True)
            logger.error(f'æ•´ç†å¤±è´¥: {e}')
            
            # å‘é€ Telegram å¤±è´¥é€šçŸ¥
            movie_id = movie.dvdid or movie.cid
            notifier.send_error_notification(
                movie_id=movie_id,
                error_message=str(e)
            )
            
            failed_count += 1
        finally:
            # æ¸…é™¤å½“å‰å½±ç‰‡ä¿¡æ¯
            set_current_movie_info(None)
            inner_bar.close()
    
    # å‘é€æ‰¹é‡æ•´ç†å®Œæˆçš„æ±‡æ€»é€šçŸ¥
    total_count = len(all_movies)
    notifier.send_batch_summary(
        total=total_count,
        success=success_count,
        failed=failed_count
    )
    
    return return_movies


def download_cover(covers, fanart_path, big_covers=[]):
    """ä¸‹è½½å°é¢å›¾ç‰‡"""
    # ä¼˜å…ˆä¸‹è½½é«˜æ¸…å°é¢
    for url in big_covers:
        pic_path = get_pic_path(fanart_path, url)
        for _ in range(Cfg().network.retry):
            try:
                info = download(url, pic_path)
                if valid_pic(pic_path):
                    filesize = get_fmt_size(pic_path)
                    width, height = get_pic_size(pic_path)
                    elapsed = time.strftime("%M:%S", time.gmtime(info['elapsed']))
                    speed = get_fmt_size(info['rate']) + '/s'
                    logger.info(f"å·²ä¸‹è½½é«˜æ¸…å°é¢: {width}x{height}, {filesize} [{elapsed}, {speed}]")
                    return (url, pic_path)
            except requests.exceptions.HTTPError:
                # HTTPErroré€šå¸¸è¯´æ˜çŒœæµ‹çš„é«˜æ¸…å°é¢åœ°å€å®é™…ä¸å¯ç”¨ï¼Œå› æ­¤ä¸å†é‡è¯•
                break
    # å¦‚æœæ²¡æœ‰é«˜æ¸…å°é¢æˆ–é«˜æ¸…å°é¢ä¸‹è½½å¤±è´¥
    for url in covers:
        pic_path = get_pic_path(fanart_path, url)
        for _ in range(Cfg().network.retry):
            try:
                download(url, pic_path)
                if valid_pic(pic_path):
                    logger.debug(f"å·²ä¸‹è½½å°é¢: '{url}'")
                    return (url, pic_path)
                else:
                    logger.debug(f"å›¾ç‰‡æ— æ•ˆæˆ–å·²æŸå: '{url}'ï¼Œå°è¯•æ›´æ¢ä¸‹è½½åœ°å€")
                    break
            except Exception as e:
                logger.debug(e, exc_info=True)
    logger.error(f"ä¸‹è½½å°é¢å›¾ç‰‡å¤±è´¥")
    logger.debug('big_covers:'+str(big_covers) + ', covers'+str(covers))
    return None

def get_pic_path(fanart_path, url):
    fanart_base = os.path.splitext(fanart_path)[0]
    pic_extend = url.split('.')[-1]
    # åˆ¤æ–­ url æ˜¯å¦å¸¦ï¼Ÿåé¢çš„å‚æ•°
    if '?' in pic_extend:
        pic_extend = pic_extend.split('?')[0]
        
    pic_path = fanart_base + "." + pic_extend
    return pic_path

def error_exit(success, err_info):
    """æ£€æŸ¥ä¸šåŠ¡é€»è¾‘æ˜¯å¦æˆåŠŸå®Œæˆï¼Œå¦‚æœå¤±è´¥åˆ™æŠ¥é”™é€€å‡ºç¨‹åº"""
    if not success:
        logger.error(err_info)
        sys.exit(1)


def entry():
    try:
        Cfg()
    except ValidationError as e:
        print(e.errors())
        exit(1)

    global actressAliasMap
    if Cfg().crawler.normalize_actress_name:
        actressAliasFilePath = resource_path("data/actress_alias.json")
        with open(actressAliasFilePath, "r", encoding="utf-8") as file:
            actressAliasMap = json.load(file)

    colorama.init(autoreset=True)

    # æ£€æŸ¥æ›´æ–°
    version_info = 'JavSP ' + getattr(sys, 'javsp_version', 'æœªçŸ¥ç‰ˆæœ¬/ä»ä»£ç è¿è¡Œ')
    logger.debug(version_info.center(60, '='))
    check_update(Cfg().other.check_update, Cfg().other.auto_update)
    root = get_scan_dir(Cfg().scanner.input_directory)
    error_exit(root, 'æœªé€‰æ‹©è¦æ‰«æçš„æ–‡ä»¶å¤¹')
    # å¯¼å…¥æŠ“å–å™¨ï¼Œå¿…é¡»åœ¨chdirä¹‹å‰
    import_crawlers()
    os.chdir(root)

    print(f'æ‰«æå½±ç‰‡æ–‡ä»¶...')
    recognized = scan_movies(root)
    movie_count = len(recognized)
    recognize_fail = []
    error_exit(movie_count, 'æœªæ‰¾åˆ°å½±ç‰‡æ–‡ä»¶')
    logger.info(f'æ‰«æå½±ç‰‡æ–‡ä»¶ï¼šå…±æ‰¾åˆ° {movie_count} éƒ¨å½±ç‰‡')
    if Cfg().scanner.manual:
        reviewMovieID(recognized, root)
    RunNormalMode(recognized + recognize_fail)

    sys.exit(0)

if __name__ == "__main__":
    entry()
